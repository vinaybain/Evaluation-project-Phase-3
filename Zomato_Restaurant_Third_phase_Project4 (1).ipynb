{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFNineegvwZh"
   },
   "source": [
    "**Zomato Restaurant Project Description :**\n",
    "Zomato Data Analysis is one of the most useful analysis for foodies who want to taste the best\n",
    "\n",
    "cuisines of every part of the world which lies in their budget. This analysis is also for those who want to find the value for money restaurants in various parts of the country for the cuisines.\n",
    "\n",
    "Additionally, this analysis caters the needs of people who are striving to get the best cuisine of the country and which locality of that country serves that cuisines with maximum number of restaurants.\n",
    "\n",
    "\n",
    "**Data Storage:**\n",
    "This problem statement contains two datasets- Zomato.csv and country_code.csv.\n",
    "Country_code.csv contains two variables:\n",
    "\n",
    "##• Country code\n",
    "##• Country name\n",
    "\n",
    "The collected data has been stored in the Comma Separated Value file Zomato.csv.\n",
    "\n",
    "  Each restaurant in the dataset is uniquely identified by its Restaurant Id. **Every Restaurant contains the following variables:**\n",
    "\n",
    "• Restaurant Id: Unique id of every restaurant across various cities of the world\n",
    "\n",
    "• Restaurant Name: Name of the restaurant\n",
    "\n",
    "• Country Code: Country in which restaurant is located\n",
    "\n",
    "• City: City in which restaurant is located\n",
    "\n",
    "• Address: Address of the restaurant\n",
    "\n",
    "• Locality: Location in the city\n",
    "\n",
    "• Locality Verbose: Detailed description of the locality\n",
    "\n",
    "• Longitude: Longitude coordinate of the restaurant&#39;s location\n",
    "\n",
    "• Latitude: Latitude coordinate of the restaurant&#39;s location\n",
    "\n",
    "• Cuisines: Cuisines offered by the restaurant\n",
    "\n",
    "• Average Cost for two: Cost for two people in different currencies\n",
    "\n",
    "• Currency: Currency of the country\n",
    "\n",
    "• Has Table booking: yes/no\n",
    "\n",
    "• Has Online delivery: yes/ no\n",
    "\n",
    "• Is delivering: yes/ no\n",
    "\n",
    "• Switch to order menu: yes/no\n",
    "\n",
    "• Price range: range of price of food\n",
    "\n",
    "• Aggregate Rating: Average rating out of 5\n",
    "\n",
    "• Rating color: depending upon the average rating color\n",
    "\n",
    "• Rating text: text on the basis of rating of rating\n",
    "\n",
    "• Votes: Number of ratings casted by people\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4DT97d-v5-P"
   },
   "source": [
    "\n",
    "**Problem statement :**\n",
    "\n",
    "In this dataset predict 2 things –\n",
    "1) Average Cost for two\n",
    "2) Price range\n",
    "\n",
    "\n",
    "Hint : Use pandas methods to combine all the datasets and then start working on this project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYiTXmZ-wBFu"
   },
   "source": [
    "**Dataset Link-**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DlPwwHzQv487"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7IXVPLcuy2FX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Data Loading and Merging the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df1_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/dsrscientist/dataset4/blob/main/zomato.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(df1_url,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Data Loading and Merging the data\n",
    "df1_url = 'https://github.com/dsrscientist/dataset4/blob/main/zomato.csv'\n",
    "df2_url = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Z_Restaurant/Country-Code.xlsx'\n",
    "df1 = pd.read_csv(df1_url,encoding='latin-1')\n",
    "df2 = pd.read_excel(df2_url)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6WLQTzAfLRW"
   },
   "outputs": [],
   "source": [
    "print(df1.columns)\n",
    "\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYfjJHIH4xJO"
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEbvhUl942RW"
   },
   "outputs": [],
   "source": [
    "df_zomoto = pd.merge(df1,df2,on='Country Code',how='left')\n",
    "df_zomoto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuEnFYfng4kZ"
   },
   "source": [
    "**Exploratory Data Analysis (EDA):**\n",
    "\n",
    "Perform EDA to understand the distribution of features, handle missing values, and identify correlations.\n",
    "\n",
    "Visualize data to find insights about the restaurant locations, cuisines, and pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lv7gJPjdhMxY"
   },
   "outputs": [],
   "source": [
    "df_zomoto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv4y0EPPhnAn"
   },
   "outputs": [],
   "source": [
    "df_zomoto.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lt8rlJDRECXu"
   },
   "outputs": [],
   "source": [
    "df_zomoto.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_jTu--_EBLS"
   },
   "source": [
    "##Exploratory Data analysis (EDA)\n",
    "We can see ,there is no missing values in the columns in our dataset\n",
    "we will check again if  any duplicates and missing values  in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQLbXWLYEAuu"
   },
   "outputs": [],
   "source": [
    "df_zomoto.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvflP34PEvPY"
   },
   "outputs": [],
   "source": [
    "df_zomoto.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoZ4HC5cEyc2"
   },
   "outputs": [],
   "source": [
    "#Distrubution of average Cost for two\n",
    "#Distplot\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(df_zomoto['Average Cost for two'], bins=50,kde =True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F69ciP86FPW9"
   },
   "outputs": [],
   "source": [
    "#Histplot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df_zomoto['Average Cost for two'], bins=50,kde =True)\n",
    "plt.title('Average Cost for two')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-6Eyni1Fx4T"
   },
   "outputs": [],
   "source": [
    "#Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "corr = df_zomoto.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr,annot=True,cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZGDU6OyJ_I8"
   },
   "source": [
    "As per the above heatmap , there is no significant correlation between 'Average Cost for two ' and other fatures\n",
    "\n",
    "The correlation are relatively low  ,with the highest being a weak positive correlation of 0.075 with **prince Range**\n",
    "\n",
    "**Price Range :** Price range have some moderate positive correlaion with '**aggregate rating**  and **Votes** i.e 0.44 and 0.31\n",
    "this suggestes that highest priced restartents tend to have better ratings and more votes\n",
    "\n",
    "aggregate rating vs votes : 0.31\n",
    "aggregate rating vs Price range 0.44\n",
    "price range vs votes : 0.31\n",
    "\n",
    "**Country Code**  has a moderate negitive correlation with 'longitude'(-0.70).\n",
    "\n",
    "this likely reflects geograpical clustering of the data,where certain country codes are associated with specific longitude ranges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2vLT9lGzj8w"
   },
   "outputs": [],
   "source": [
    "df_zomoto.columns\n",
    "print(df_zomoto.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgB945WuyZvc"
   },
   "outputs": [],
   "source": [
    "skewness = df_zomoto.select_dtypes(include=[np.number]).skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHxDFmVP0Yrx"
   },
   "source": [
    "#Skewness result is :\n",
    "\n",
    "Restaurant ID 0.061570\n",
    "Country Code 3.043965\n",
    " Longitude -2.807328\n",
    " Latitude -3.081635\n",
    "  Average Cost for two 35.477915\n",
    "   Price range 0.889618\n",
    "   Aggregate rating -0.954130\n",
    "   Votes 8.807637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJJbz25G1ivL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Gk3g4pN0qgZ"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer\n",
    "\n",
    "num_cols = ['Restaurant ID','Country Code','Longitude','Latitude','Average Cost for two','Price range','Aggregate rating','Votes']\n",
    "\n",
    "df_zomoto['Average Cost for two'] = np.log1p(df_zomoto['Average Cost for two'])\n",
    "df_zomoto['Votes'] = np.log1p(df_zomoto['Votes'])\n",
    "\n",
    "#Power transfer method\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "df_zomoto[num_cols] = power_transformer.fit_transform(df_zomoto[num_cols])\n",
    "\n",
    "#StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_zomoto[num_cols] = scaler.fit_transform(df_zomoto[num_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA56SF0d2EOH"
   },
   "outputs": [],
   "source": [
    "df_zomoto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWia7DHc2V2G"
   },
   "outputs": [],
   "source": [
    "#second time\n",
    "skewness = df_zomoto.select_dtypes(include=[np.number]).skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ah7IPH1Z3mHq"
   },
   "outputs": [],
   "source": [
    "high_skew_col = ['Country Code', 'Longitude','Latitude']\n",
    "\n",
    "for col in high_skew_col:\n",
    "  df_zomoto[col] = power_transformer.fit_transform(df_zomoto[[col]])\n",
    "\n",
    "  scaler1 = StandardScaler()\n",
    "  df_zomoto[col] = scaler1.fit_transform(df_zomoto[[col]])\n",
    "\n",
    "skewness = df_zomoto.select_dtypes(include=[np.number]).skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPcNSA8l1BpQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdOjfx4Z0FpK"
   },
   "source": [
    "Before Proceeding with model deployment ,we need to encode the catagerical features into numerical values\n",
    "\n",
    "There are ⁉\n",
    "**Label Encoding:** Assigns each unique category a different integer. This can be used when there is an ordinal relationship between categories\n",
    "\n",
    "**One-Hot Encoding:** Creates binary columns for each category. This is used when there is no ordinal relationship between categories\n",
    "\n",
    "**we will apply the following encoding strategies:**\n",
    "**Label Encoding** for columns where ordinal relationship might exist or where we have a small number of unique values\n",
    "**One-Hot Encoding** for columns with no ordinal relationship and a manageable number of unique values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UJ2kNVa0_Yr"
   },
   "outputs": [],
   "source": [
    "label_cols = ['Has Table booking','Has Online delivery','Is delivering now','Switch to order menu','Rating color','Rating text']\n",
    "onehot_cols = ['Country','City','Address','Locality','Locality Verbose','Cuisines','Currency','Restaurant Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLFoZ9T71qYy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le_encode = LabelEncoder()\n",
    "for col in label_cols:\n",
    "  df_zomoto[col] = le_encode.fit_transform(df_zomoto[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1CjLEp714vQ"
   },
   "outputs": [],
   "source": [
    "#one hot encoder\n",
    "df_zomoto = pd.get_dummies(df_zomoto,columns=onehot_cols)\n",
    "df_zomoto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvTPRC8Y2D9z"
   },
   "outputs": [],
   "source": [
    "#after encoding the dataset\n",
    "df_zomoto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLpB420IMM1q"
   },
   "outputs": [],
   "source": [
    "df_zomoto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiwY4xZxLGvx"
   },
   "outputs": [],
   "source": [
    "#Encoding False and True Values\n",
    "boolean_col = ['Restaurant Name_feel ALIVE','Restaurant Name_hug!',\n",
    "       'Restaurant Name_iGNiTE', 'Restaurant Name_iKitchen',\n",
    "       'Restaurant Name_sketch Gallery', 'Restaurant Name_t Lounge by Dilmah',\n",
    "       'Restaurant Name_tashas', 'Restaurant Name_wagamama',\n",
    "       'Restaurant Name_{Niche} - Cafe & Bar',\n",
    "       'Restaurant Name_íukuraÛôa SofrasÛ±']\n",
    "for col in boolean_col:\n",
    "  df_zomoto[col] = df_zomoto[col].replace({False:0,True:1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4GJXm8yM6bl"
   },
   "outputs": [],
   "source": [
    "print(df_zomoto.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YnLwXDfNG0T"
   },
   "outputs": [],
   "source": [
    "print(df_zomoto.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWqZ7nAPvJwI"
   },
   "source": [
    "##Predicting average cost for two\n",
    "\n",
    "we'll use regression models such as linear regression,desision trees and random forests to predict average cost for two\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6PWy1emwMjN"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install nvidia-cublas-cu12==12.1.3.1\n",
    "!pip install nvidia-cuda-cupti-cu12==12.1.105\n",
    "!pip install nvidia-cuda-runtime-cu12==12.1.105\n",
    "!pip install nvidia-cudnn-cu12==8.9.2.26\n",
    "!pip install nvidia-cufft-cu12==11.0.2.54\n",
    "!pip install nvidia-curand-cu12==10.3.2.106\n",
    "!pip install nvidia-cusolver-cu12==11.4.5.107\n",
    "!pip install nvidia-cusparse-cu12==12.1.0.106\n",
    "!pip install nvidia-nvtx-cu12==12.1.105\n",
    "!pip install nvidia-nccl-cu12==2.20.5\n",
    "!pip install nvidia-nsight-cu12==2.20.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yTGnORnlEmr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_score,recall_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azwn4deMzVvt"
   },
   "outputs": [],
   "source": [
    "#feature and target variables\n",
    "features = df_zomoto.drop(['Average Cost for two','Price range'],axis=1)\n",
    "target_cost = df_zomoto['Average Cost for two']\n",
    "target_price = df_zomoto['Price range']\n",
    "\n",
    "#Train and test split\n",
    "X_train_cost,X_test_cost,y_train_cost,y_test_cost = train_test_split(features,target_cost,test_size=0.2,random_state=42)\n",
    "X_train_price,X_test_price,y_train_price,y_test_price = train_test_split(features,target_price,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_cost = scaler.fit_transform(X_train_cost)\n",
    "X_test_cost = scaler.transform(X_test_cost)\n",
    "\n",
    "#applying PCA to reduce the number of features\n",
    "PCA_cost = PCA(n_components=10)\n",
    "X_train_cost = PCA_cost.fit_transform(X_train_cost)\n",
    "X_test_cost = PCA_cost.transform(X_test_cost)\n",
    "\n",
    "rf_model_cost = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "rf_model_cost.fit(X_train_cost,y_train_cost)\n",
    "y_pred_rf_cost = rf_model_cost.predict(X_test_cost)\n",
    "\n",
    "rmse_cose = mean_squared_error(y_test_cost,y_pred_rf_cost,squared=False)\n",
    "print(\"RandomForestRegressor - Root mean squared error(Cost):\",rmse_cose)\n",
    "print(\"RandomForestRegressor -Mean absolute error(Cost):\",mean_absolute_error(y_test_cost,y_pred_rf_cost))\n",
    "print(\"RandomForestRegressor -R2 score(Cost):\",r2_score(y_test_cost,y_pred_rf_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmmNpBMz9G0F"
   },
   "outputs": [],
   "source": [
    "#RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "#Price range\n",
    "# Price using classifier\n",
    "X_train_price = scaler.fit_transform(X_train_price)\n",
    "X_test_price = scaler.transform(X_test_price)\n",
    "\n",
    "#applying PCA to reduce the number of features\n",
    "PCA_price = PCA(n_components=10)\n",
    "X_train_price = PCA_price.fit_transform(X_train_price)\n",
    "X_test_price = PCA_price.transform(X_test_price)\n",
    "\n",
    "\n",
    "rfr_model_price = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "rfr_model_price.fit(X_train_price,y_train_price)\n",
    "y_pred_rfr_price = rfr_model_price.predict(X_test_price)\n",
    "\n",
    "rmse_price = mean_squared_error(y_test_price,y_pred_rfr_price,squared=False)\n",
    "print(\"RandomForestRegressor- Root mean squared error(Price):\",rmse_price)\n",
    "print(\"RandomForestRegressor-Mean absolute error(Price):\",mean_absolute_error(y_test_price,y_pred_rfr_price))\n",
    "print(\"RandomForestRegressor-R2 score(Price):\",r2_score(y_test_price,y_pred_rfr_price))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRRhh6xEJxsr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSVCacLZjRUT"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100,150],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'learning_rate' : [0.01,0.1,1]\n",
    "}\n",
    "\n",
    "XGB_model_cost = XGBRegressor()\n",
    "XGB_GridSearch_cost = GridSearchCV(estimator=XGB_model_cost, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "XGB_GridSearch_cost.fit(X_train_cost,y_train_cost)\n",
    "\n",
    "best_params = XGB_GridSearch_cost.best_params_\n",
    "print(\"Best parameters:\",best_params)\n",
    "\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train_cost,y_train_cost)\n",
    "\n",
    "y_pred_XGB_cost = best_model.predict(X_test_cost)\n",
    "\n",
    "\n",
    "rmse = mean_squared_error(y_test_cost,y_pred_XGB_cost,squared=False)\n",
    "print(\"XGBRegressor-Root mean squared error(Cost):\",rmse)\n",
    "print(\"XGBRegressor-Mean absolute error(Cost):\",mean_absolute_error(y_test_cost,y_pred_XGB_cost))\n",
    "print(\"XGBRegressor-R2 score(Cost):\",r2_score(y_test_cost,y_pred_XGB_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcHzBEXzRdOL"
   },
   "source": [
    "Best parameters: {'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
    "XGBRegressor-Root mean squared error(Cost): 0.5976602952205758\n",
    "XGBRegressor-Mean absolute error(Cost): 0.43896865236483845\n",
    "XGBRegressor-R2 score(Cost): 0.6368710783978982\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I33DEQ_uSLvg"
   },
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "ploy_cost = PolynomialFeatures(degree=2,include_bias=False)\n",
    "X_train_cost_poly = ploy_cost.fit_transform(X_train_cost)\n",
    "X_test_cost_poly = ploy_cost.transform(X_test_cost)\n",
    "\n",
    "ploy_price = PolynomialFeatures(degree=2,include_bias=False)\n",
    "X_train_price_poly = ploy_price.fit_transform(X_train_price)\n",
    "X_test_price_poly = ploy_price.transform(X_test_price)\n",
    "\n",
    "\n",
    "best_model.fit(X_train_cost_poly,y_train_cost)\n",
    "y_pred_XGB_cost = best_model.predict(X_test_cost_poly)\n",
    "\n",
    "\n",
    "rmse = mean_squared_error(y_test_cost,y_pred_XGB_cost,squared=False)\n",
    "print(\"PolynomialFeatures-Root mean squared error(Cost):\",rmse)\n",
    "print(\"PolynomialFeaturesMean - absolute error(Cost):\",mean_absolute_error(y_test_cost,y_pred_XGB_cost))\n",
    "print(\"PolynomialFeatures-R2 score(Cost):\",r2_score(y_test_cost,y_pred_XGB_cost))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "cell_execution_strategy": "setup",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
